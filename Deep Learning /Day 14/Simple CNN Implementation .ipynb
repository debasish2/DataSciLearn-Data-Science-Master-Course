{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8329d24",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) implementation using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe28164",
   "metadata": {},
   "source": [
    "# CNN Components Explained\n",
    "\n",
    "### Filter\n",
    "In CNNs, a filter (also known as a kernel) is a small matrix used for convolution operations. Filters are applied to input data to extract features by performing element-wise multiplication and summation with the input data.\n",
    "\n",
    "### Convolution Operation\n",
    "The convolution operation involves applying a filter to an input image or feature map. This operation calculates the dot product between the filter and a small region of the input data, moving the filter across the entire input to produce a feature map.\n",
    "\n",
    "### Convolution Layer\n",
    "A convolutional layer consists of multiple filters that are convolved with the input data. Each filter learns to detect different features in the input. The output of each filter forms a separate feature map, which is then passed through an activation function to introduce non-linearity.\n",
    "\n",
    "### Padding\n",
    "Padding is the process of adding extra border pixels to the input data before applying convolution. Padding helps preserve spatial dimensions of the input and can be used to control the size of the output feature maps.\n",
    "\n",
    "### Strides\n",
    "Strides determine the step size with which the filter moves across the input data during convolution. A stride of 1 means the filter moves one pixel at a time, while a larger stride skips pixels, resulting in smaller output feature maps.\n",
    "\n",
    "### Max Pooling\n",
    "Max pooling is a downsampling operation commonly used in CNNs to reduce the spatial dimensions of the feature maps. It involves dividing the input into non-overlapping regions and selecting the maximum value from each region to form the pooled feature map. Max pooling helps in reducing computation and controlling overfitting.\n",
    "\n",
    "### TensorFlow Implementation\n",
    "In a TensorFlow implementation, you would typically define these components using TensorFlow's high-level API, such as `tf.keras.layers.Conv2D` for convolutional layers and `tf.keras.layers.MaxPooling2D` for max pooling layers. You would also specify parameters such as filter size, padding type, stride, and pooling size according to the requirements of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7611bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244b33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input imahe shape(eg 28x28X1 for grayscale images)\n",
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030fbc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layer with 32 filters , kernel size of 3x3 , RELU activation \n",
    "    tf.keras.layers.Conv2D(filters=32 , kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
    "    \n",
    "    # Adding padding to maintain spatial dimensions\n",
    "    tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "    \n",
    "    # Convolutional layer with 64 filters , kernel size of 3x3 , RELU activation \n",
    "    tf.keras.layers.Conv2D(filters=64 , kernel_size=(3,3), activation='relu'),\n",
    "    \n",
    "    # Max pooling layer with pool size of 2X2\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    \n",
    "    # Flatten layer to convert 2D features maps into 1D feature vector \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully connected(dense) layer with units 128 and RELU activation\n",
    "    \n",
    "    tf.keras.layers.Dense(units=128 , activation='relu'),\n",
    "    \n",
    "    # Output layer with softmax activation for classification\n",
    "    \n",
    "    tf.keras.layers.Dense(units=10 , activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113399c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentrophy' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06d5230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPaddin  (None, 28, 28, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1384576   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1404682 (5.36 MB)\n",
      "Trainable params: 1404682 (5.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a883ed",
   "metadata": {},
   "source": [
    "# Explanation of Shapes\n",
    "- (None, 26, 26, 32): The first Conv2D layer outputs 32 feature maps of size 26x26 (due to the 3x3 kernel with no padding).\n",
    "- (None, 28, 28, 32): The ZeroPadding2D layer adds padding, restoring the size to 28x28.\n",
    "- (None, 26, 26, 64): The second Conv2D layer outputs 64 feature maps of size 26x26.\n",
    "- (None, 13, 13, 64): The MaxPooling2D layer reduces the size by half to 13x13.\n",
    "- (None, 10816): The Flatten layer reshapes the 13x13x64 feature maps into a 1D vector.\n",
    "- (None, 128): The first Dense layer reduces the 10816 features to 128 units.\n",
    "- (None, 10): The output Dense layer reduces the 128 units to 10 units (for classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d867c1c",
   "metadata": {},
   "source": [
    "## Why Not Use 1D or 3D?\n",
    "##### 1D Layers (Conv1D, MaxPooling1D): Used for sequential data, like time series or audio signals, where the data has a single spatial dimension.\n",
    "###### 3D Layers (Conv3D, MaxPooling3D): Used for volumetric data, like video or 3D medical imaging, where the data has three spatial dimensions (height, width, and depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352e661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
