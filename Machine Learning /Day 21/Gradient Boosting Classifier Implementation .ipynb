{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bfadab",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "The Gradient Boosting Classifier is a machine learning algorithm used for classification tasks. It belongs to the family of boosting algorithms and is based on the principle of ensemble learning. Gradient Boosting combines multiple weak learners (typically decision trees) to create a strong learner that can make accurate predictions.\n",
    "\n",
    "Here's how Gradient Boosting Classifier works:\n",
    "\n",
    "1. Initialization:\n",
    "\n",
    "- The algorithm starts with an initial guess for the target variable, usually the class distribution or the log-odds for each     class.\n",
    "- The initial prediction is often set as the average of the target variable for regression tasks or the logarithm of the class     probabilities for classification tasks.\n",
    "\n",
    "2. Building Weak Learners (Decision Trees):\n",
    "\n",
    "- Gradient Boosting builds a series of decision trees sequentially, with each tree trained to correct the errors made by the previous ones.\n",
    "- Each decision tree is a weak learner, meaning it performs slightly better than random guessing but is not very accurate on its own.\n",
    "- Decision trees are typically shallow to prevent overfitting.\n",
    "\n",
    "3. Calculating Pseudo-Residuals:\n",
    "\n",
    "- At each iteration, the algorithm calculates the pseudo-residuals, which represent the negative gradient of the loss function with respect to the current prediction.\n",
    "\n",
    "- The pseudo-residuals indicate how much the current model's predictions differ from the actual target values.\n",
    "\n",
    "4. Fitting Weak Learners to Pseudo-Residuals:\n",
    "\n",
    "- The next decision tree is trained to predict the pseudo-residuals of the previous model.\n",
    "- The new tree is fit to the pseudo-residuals using techniques like gradient descent.\n",
    "\n",
    "5. Updating Predictions:\n",
    "\n",
    "- The predictions of all the weak learners are combined to make the final prediction.\n",
    "\n",
    "- Each weak learner's prediction is weighted based on its contribution to minimizing the loss function.\n",
    "\n",
    "6. Regularization:\n",
    "\n",
    "- Gradient Boosting often includes regularization techniques to prevent overfitting, such as limiting the depth of the trees, adding learning rate parameters, or using early stopping.\n",
    "\n",
    "7. Final Prediction:\n",
    "\n",
    "- The final prediction is made by aggregating the predictions of all the weak learners.\n",
    "- For classification tasks, the class with the highest probability is chosen as the predicted class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7e3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa68a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b22d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb528aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gradient Boosting Classifier\n",
    "n_estimators = 100  # Number of weak learners\n",
    "learning_rate = 0.1  # Learning rate\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4215aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Gradient Boosting Classifier\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7845afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = gb_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130f5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cddccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0fccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
