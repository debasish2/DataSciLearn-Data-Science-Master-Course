{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6344e4",
   "metadata": {},
   "source": [
    "# 1. Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3b5e3",
   "metadata": {},
   "source": [
    "For language modeling, we'll use nltk's bigrams and trigrams functions to demonstrate a simple n-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c321c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba00c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text \n",
    "text = \"The cat sat on the mat. The dog lay on the mat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1911b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'sat', 'on', 'the', 'mat', '.', 'the', 'dog', 'lay', 'on', 'the', 'mat', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text.lower())\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a16a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'cat'), ('cat', 'sat'), ('sat', 'on'), ('on', 'the'), ('the', 'mat'), ('mat', '.'), ('.', 'the'), ('the', 'dog'), ('dog', 'lay'), ('lay', 'on'), ('on', 'the'), ('the', 'mat'), ('mat', '.')]\n",
      "[('the', 'cat', 'sat'), ('cat', 'sat', 'on'), ('sat', 'on', 'the'), ('on', 'the', 'mat'), ('the', 'mat', '.'), ('mat', '.', 'the'), ('.', 'the', 'dog'), ('the', 'dog', 'lay'), ('dog', 'lay', 'on'), ('lay', 'on', 'the'), ('on', 'the', 'mat'), ('the', 'mat', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Generate bigrams and trigrams\n",
    "bigrams = list(ngrams(tokens,2))\n",
    "trigrams = list(ngrams(tokens,3))\n",
    "\n",
    "print(bigrams)\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd19be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Distribution\n",
    "bigrams_freq = Counter(bigrams)\n",
    "trigrams_freq = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14fcb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "Counter({('on', 'the'): 2, ('the', 'mat'): 2, ('mat', '.'): 2, ('the', 'cat'): 1, ('cat', 'sat'): 1, ('sat', 'on'): 1, ('.', 'the'): 1, ('the', 'dog'): 1, ('dog', 'lay'): 1, ('lay', 'on'): 1})\n",
      "\n",
      "Trigrams:\n",
      "Counter({('on', 'the', 'mat'): 2, ('the', 'mat', '.'): 2, ('the', 'cat', 'sat'): 1, ('cat', 'sat', 'on'): 1, ('sat', 'on', 'the'): 1, ('mat', '.', 'the'): 1, ('.', 'the', 'dog'): 1, ('the', 'dog', 'lay'): 1, ('dog', 'lay', 'on'): 1, ('lay', 'on', 'the'): 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigrams:\")\n",
    "print(bigrams_freq)\n",
    "print(\"\\nTrigrams:\")\n",
    "print(trigrams_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc8c5a",
   "metadata": {},
   "source": [
    "# 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddab9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'the')\n",
      "('the', 'cat')\n",
      "('cat', 'is')\n",
      "('is', 'on')\n",
      "('on', 'the')\n",
      "('the', 'mat')\n",
      "('mat', '.')\n",
      "('.', '</s>')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import bigrams\n",
    "from nltk.lm.preprocessing import pad_both_ends, flatten\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The cat is on the mat.\"\n",
    "\n",
    "# Tokenize and create bigrams\n",
    "tokens = nltk.word_tokenize(sentence.lower())\n",
    "bigram_model = list(bigrams(pad_both_ends(tokens, n=2)))\n",
    "\n",
    "# Print bigrams\n",
    "for bigram in bigram_model:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44570afc",
   "metadata": {},
   "source": [
    "# 2. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967ad85",
   "metadata": {},
   "source": [
    "We can create n-grams using nltk's ngrams function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c741688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-grams:\n",
      "[('the', 'cat', 'is'), ('cat', 'is', 'on'), ('is', 'on', 'the'), ('on', 'the', 'mat'), ('the', 'mat', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Generate n-grams (e.g., trigrams)\n",
    "n = 3\n",
    "n_grams = list(ngrams(tokens, n))\n",
    "\n",
    "print(f\"{n}-grams:\")\n",
    "print(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad540d5c",
   "metadata": {},
   "source": [
    "# 3. Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2632dced",
   "metadata": {},
   "source": [
    "A Bag of Words model can be implemented by counting word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83b8c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d99907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d32a3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency distribution\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for word in words:\n",
    "    word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff1b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words:\n",
      "{'the': 4, 'cat': 1, 'sat': 1, 'on': 2, 'mat': 2, '.': 2, 'dog': 1, 'lay': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words:\")\n",
    "print(dict(word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0a02cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 BoW: {'the': 2, 'cat': 1, 'sat': 1, 'on': 1, 'mat': 1, '.': 1}\n",
      "Document 2 BoW: {'the': 2, 'dog': 1, 'lay': 1, 'on': 1, 'mat': 1, '.': 1}\n"
     ]
    }
   ],
   "source": [
    "# 2nd Method\n",
    "doc1 = \"The cat sat on the mat.\"\n",
    "doc2 = \"The dog lay on the mat.\"\n",
    "# Tokenize and create BoW representation\n",
    "tokens1 = nltk.word_tokenize(doc1.lower())\n",
    "tokens2 = nltk.word_tokenize(doc2.lower())\n",
    "bow1 = Counter(tokens1)\n",
    "bow2 = Counter(tokens2)\n",
    "\n",
    "# Print BoW vectors\n",
    "print(\"Document 1 BoW:\", dict(bow1))\n",
    "print(\"Document 2 BoW:\", dict(bow2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3fd8e5",
   "metadata": {},
   "source": [
    "# 4. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178fa01",
   "metadata": {},
   "source": [
    "For TF-IDF, we'll use nltk along with sklearn's TfidfVectorizer for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9fee85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fc9b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog lay on the mat.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7742beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5074aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44554752, 0.        , 0.        , 0.31701073, 0.31701073,\n",
       "        0.44554752, 0.63402146],\n",
       "       [0.        , 0.44554752, 0.44554752, 0.31701073, 0.31701073,\n",
       "        0.        , 0.63402146]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "570c92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2df68d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 TF-IDF Scores:\n",
      "cat: 0.4455\n",
      "dog: 0.0000\n",
      "lay: 0.0000\n",
      "mat: 0.3170\n",
      "on: 0.3170\n",
      "sat: 0.4455\n",
      "the: 0.6340\n",
      "\n",
      "Document 2 TF-IDF Scores:\n",
      "cat: 0.0000\n",
      "dog: 0.4455\n",
      "lay: 0.4455\n",
      "mat: 0.3170\n",
      "on: 0.3170\n",
      "sat: 0.0000\n",
      "the: 0.6340\n"
     ]
    }
   ],
   "source": [
    "# Print the TF-IDF scores\n",
    "for doc_index, doc in enumerate(tfidf_matrix.toarray()):\n",
    "    print(f\"\\nDocument {doc_index + 1} TF-IDF Scores:\")\n",
    "    for word_index, score in enumerate(doc):\n",
    "        print(f\"{feature_names[word_index]}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e90154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
