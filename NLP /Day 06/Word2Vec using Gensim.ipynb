{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5355223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472b594",
   "metadata": {},
   "source": [
    "# 1. Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b9fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7845f9",
   "metadata": {},
   "source": [
    "# 2. Defining Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ae92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"machine learning is great\",\n",
    "    \"natural language processing and machine learning are amazing\",\n",
    "    \"word embeddings are useful for many natural language processing tasks\",\n",
    "    \"deep learning models can outperform traditional machine learning algorithms\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b4fb7",
   "metadata": {},
   "source": [
    "# 3. Tokenizing Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc1aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learning', 'is', 'great'], ['natural', 'language', 'processing', 'and', 'machine', 'learning', 'are', 'amazing'], ['word', 'embeddings', 'are', 'useful', 'for', 'many', 'natural', 'language', 'processing', 'tasks'], ['deep', 'learning', 'models', 'can', 'outperform', 'traditional', 'machine', 'learning', 'algorithms']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c411efa",
   "metadata": {},
   "source": [
    "# 4. Training CBOW Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4b398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_model = Word2Vec(sentences=tokenized_sentences, vector_size=100 , window=5 , min_count=1, workers=4 , sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8538",
   "metadata": {},
   "source": [
    "- min_count=1: Ignores all words with a total frequency lower than this value.\n",
    "- workers=4: Sets the number of worker threads to train the model in parallel, leveraging multicore machines for faster training.\n",
    "- sg=0: Specifies the training algorithm. sg=0 indicates CBOW (Continuous Bag of Words).\n",
    "- vector_size=100: Sets the dimensionality of the word vectors to 100.\n",
    "- window=5: Defines the maximum distance between the current and predicted word within a sentence (context window)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74731f",
   "metadata": {},
   "source": [
    "# 5. Training Skip-gram model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c06aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893cb27",
   "metadata": {},
   "source": [
    "- sg=1: Specifies the training algorithm. sg=1 indicates Skip-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ba0d8",
   "metadata": {},
   "source": [
    "# 6. Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb27639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_model.save(\"cbow_word2vec.model\")\n",
    "skipgram_model.save(\"skipgram_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa7597",
   "metadata": {},
   "source": [
    "# 7.Loading the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c02649",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_model= Word2Vec.load(\"cbow_word2vec.model\")\n",
    "skipgram_model = Word2Vec.load(\"skipgram_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c1a4c",
   "metadata": {},
   "source": [
    "# 8. Using the CBOW model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "909e3835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW Vector for 'machine': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
      "CBOW Words similar to 'machine': [('for', 0.1607067584991455), ('models', 0.15923379361629486), ('useful', 0.13725273311138153), ('many', 0.12300865352153778), ('deep', 0.08545127511024475)]\n",
      "CBOW Similarity between 'machine' and 'learning': -0.010944764\n"
     ]
    }
   ],
   "source": [
    "cbow_vector = cbow_model.wv['machine']\n",
    "print(\"CBOW Vector for 'machine':\", cbow_vector)\n",
    "\n",
    "cbow_similar_words = cbow_model.wv.most_similar('machine', topn=5)\n",
    "print(\"CBOW Words similar to 'machine':\", cbow_similar_words)\n",
    "\n",
    "cbow_similarity = cbow_model.wv.similarity('machine', 'learning')\n",
    "print(\"CBOW Similarity between 'machine' and 'learning':\", cbow_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be859b",
   "metadata": {},
   "source": [
    "- cbow_model.wv['machine']: Retrieves the vector representation of the word 'machine' from the CBOW model.\n",
    "- cbow_model.wv.most_similar('machine', topn=5): Finds the top 5 words most similar to 'machine' based on cosine similarity in the CBOW model.\n",
    "- cbow_model.wv.similarity('machine', 'learning'): Computes the cosine similarity between the vectors of 'machine' and 'learning' in the CBOW model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a022f9ee",
   "metadata": {},
   "source": [
    "# 9. Using the Skip-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb2f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram Vector for 'machine': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
      "Skip-gram Words similar to 'machine': [('for', 0.16076719760894775), ('models', 0.15923379361629486), ('useful', 0.13725273311138153), ('many', 0.12300866097211838), ('deep', 0.0854569599032402)]\n",
      "Skip-gram Similarity between 'machine' and 'learning': -0.010759768\n"
     ]
    }
   ],
   "source": [
    "skipgram_vector = skipgram_model.wv['machine']\n",
    "print(\"Skip-gram Vector for 'machine':\", skipgram_vector)\n",
    "\n",
    "skipgram_similar_words = skipgram_model.wv.most_similar('machine', topn=5)\n",
    "print(\"Skip-gram Words similar to 'machine':\", skipgram_similar_words)\n",
    "\n",
    "skipgram_similarity = skipgram_model.wv.similarity('machine', 'learning')\n",
    "print(\"Skip-gram Similarity between 'machine' and 'learning':\", skipgram_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
